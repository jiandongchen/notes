# 数仓测试环境搭建过程

## 背景

在数仓从0至1搭建完成之后，很长的一段时间内，新调度的上线都缺乏有效的、全局的测试手段。一般的做法是，要上线的新脚本直接使用生产环境的数据针对这个特定脚本，进行测试。

这个做法会导致两个问题：

1. 一是开发者必须对于新开发的或者是修改的部分代码会产生怎样的作用有足够的把握，因为直接操作的是线上数据，如果波及到了不应受到影响的其他部分，虽然也能够恢复，因为有备份的存在，但是会很麻烦。
2. 二是只针对特定脚本的部分测试并不完全。因为主调度是作为一个整体在运行的，虽然这种上下游的job或者flow之间联系是比较弱的，但是偶尔也会出现新内容影响之前部分的情况进而甚至影响整个主调度的顺利执行。

针对这两个问题，自然的想到解决办法应该是开发一个数仓部分的测试环境。

那么，怎么开发呢？数仓的测试和普通后端或者说是线上平台的测试有很大不同，这种不同点主要体现在两个地方：

1. 数据
   1. 线上平台的数据一般来说是一个闭环，我处理的数据是我这个系统所产生的，模式是固定的。然而数仓不同，进入数仓的数据，一般是上游线上平台所产生的，所以会随时变化，这种变化体现在数据本身以及数据的量上。
   2. 测试的量不同，因为数仓的数据处理如果数据量不够大，或者说不够真实，会导致测试的结果和生产上运行的结果完全不同。
2. 硬件
   1. 如果想要复制一套1=1的测试系统需要投入和生产相同的硬件配置，这样对预算的要求很高。但是如果只用一套偏弱或者说低配置的测试系统又无法完全真实的推测出被测试调度在生产上的表现。

## 解决

针对上述两个问题的解决方法分别是：

1. 需要保证测试环境与生产环境的数据相同，有两种做法：第一种是复制的方式，保证生产环境的新增数据同样会在测试环境中新增，这个方式隔离的最为完全，但会消耗额外的空间以及额外的资源。第二种是直接使用生产环境的数据但要保证使用数据的隔离。我最后的做法在这两种中做了一个折中。
2. 第二个问题比较好解决，因为对于目前我们的离线数仓来说，生产的运行时间一般从第一天凌晨12点至第二天9点前。可以将中间的这段空余时间作为测试窗口。

所以最后我的方案为：

测试环境与生产环境共用一套大数据平台，数据方面也共用一个hive，但是分属两个database。测试环境的ods层表与生产环境ods层表公用底层hdfs数据只是表的元数据不同，这样当生产环境的ods层表新增分区时，只需刷新下测试环境的元数据即可，不涉及数据。测试环境的测试窗口为每日12点后，与生产互不影响。

## 代码修改

1. ods层同步脚本

   1. 表同步：

      ```shell
      #!/bin/bash
       
      if [ $# -ne 2 ]
      then
          echo "Usage: $0 <databasename> <newdatabasename>"
          exit 1
      fi
      
      DIR=$( dirname $0)
      DB_NAME="${1}"
      NEW_DB_NAME="${2}"
      HIVE="hive -S"
      cd $DIR/$DB_NAME
      tables="`ls *.ddl`"
      
      BATCH_SIZE=20
      PROCESS_IDX=0
      for table in $tables
      do
          PROCESS_IDX=`expr $PROCESS_IDX + 1`
      
          {
              echo "===PROCESS_IDX=$PROCESS_IDX===, Working on table: $table..."
              TABLE_NAME="`basename $table .ddl`"
      	    
              # Create table defintion in new database
              sed -i 's?CREATE TABLE?CREATE EXTERNAL TABLE?' $table
              sed -i 's?CREATE EXTERNAL TABLE IF NOT EXISTS?CREATE EXTERNAL TABLE?' $table
              sed -i 's?CREATE EXTERNAL TABLE?CREATE EXTERNAL TABLE IF NOT EXISTS?' $table
              
              # echo $( < ${table}) 
              hive --database ${NEW_DB_NAME} -S -f ${table}
      	    
              # Repair partitions for Hive
              hive --database ${NEW_DB_NAME} -S -e "MSCK REPAIR TABLE ${TABLE_NAME}"
              echo "===PROCESS_IDX=$PROCESS_IDX===, table: ${TABLE_NAME} is done."
      	} &
      
      	if [[ `expr $PROCESS_IDX % $BATCH_SIZE` == 0 ]] && [[ $PROCESS_IDX > 0 ]];then
            echo "===wait===, PROCESS_IDX=$PROCESS_IDX"
            wait
          fi
      done
      wait
      echo "===finish===, PROCESS_IDX=$PROCESS_IDX"
      ```

   2. 分区同步

      ```shell
      #!/bin/sh
      
      if [ $# -ne 1 ]
      then
              echo "Usage: $0 <databasename>"
              exit 1
      fi
      
      DIR=$( dirname $0 )
      DB_NAME="${1}"
      HIVE="hive -S"
      tables="`${HIVE} --database ${DB_NAME} -e 'show tables;'`"
      
      rm -rf $DIR/${DB_NAME} 
      mkdir -p $DIR/${DB_NAME}
      
      tables=$( echo $tables | sed 's?tab_name ??' )
      tables=$( echo $tables | sed 's?WARN: The method class org.apache.commons.logging.impl.SLF4JLogFactory#release() was invoked. WARN: Please see http://www.slf4j.org/codes.html#release for an explanation.??' )
      
      BATCH_SIZE=20
      PROCESS_IDX=0
      for table in ${tables}
      do
          if echo $table | grep -q "ods_*" && ! echo $table | grep -q "ods_stg_*"
          then
              PROCESS_IDX=`expr $PROCESS_IDX + 1`
      	    {
                  create=$( ${HIVE} --database ${DB_NAME} -e "show create table $table;" )
                  create=$( echo $create | sed 's?createtab_stmt ??')
                  create=$( echo $create | sed 's? WARN: The method class org.apache.commons.logging.impl.SLF4JLogFactory#release() was invoked. WARN: Please see http://www.slf4j.org/codes.html#release for an explanation.??')
                  echo $create > $DIR/${DB_NAME}/${table}.ddl
      		} &
          fi
      
          if [[ `expr $PROCESS_IDX % $BATCH_SIZE` == 0 ]] && [[ $PROCESS_IDX > 0 ]];then
            echo "===wait===, PROCESS_IDX=$PROCESS_IDX"
            wait
          fi
      done
      wait
      echo "===finish===, PROCESS_IDX=$PROCESS_IDX"
      ```

2. spark项目

   增加了一个database根据env变量（azkaban传入）推断的代码片段：

   ```scala
     def sql(sqlText: String): DataFrame = {
       val p = """(use )(\S*)""".r
   
       if (sqlText matches p.toString()) {
         val p(use, db) = sqlText
         spark.sql(use + inferDB(db, env))
       }
       else {
         spark.sql(sqlText)
       }
     }
   
     protected final def inferDB(db: String, env: String): String = {
       env match {
         case "prod" => db
         case "test" =>
           db match {
             case "rcm" => "rcm_test"
             case "dpm" => "dpm_test"
             case _ => db
           }
       }
     }
   ```

## 结论

暂时运行了一段时间下来，确实，在有限的资源内，解决了数仓组一直以来的没有测试环境的问题。当然这绝不是一个很完美的解决方案。之后也会在思路开阔之后想办法进行修改。